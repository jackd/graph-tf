import graph_tf.utils.models
import graph_tf.projects.mlp.data
import graph_tf.configurables

data = @gin.singleton()
data/gin.singleton.constructor = @gtf.mlp.data.get_features_split

gtf.mlp.data.get_features_split.batch_size = %batch_size
gtf.mlp.data.get_features_split.data = @gtf.mlp.data.preprocess()

gtf.mlp.data.preprocess.data = %base_data
gtf.mlp.data.preprocess.features_transform = %features_transform
gtf.mlp.data.preprocess.adjacency_features = %adjacency_features
gtf.mlp.data.preprocess.dual_features = %dual_features
gtf.mlp.data.preprocess.include_transformed_features = %include_transformed_features
gtf.mlp.data.preprocess.largest_component_only = %largest_component_only

model_fn = @gtf.utils.models.mlp
gtf.utils.models.mlp.hidden_units = %units
gtf.utils.models.mlp.output_units = %num_classes
gtf.utils.models.mlp.input_dropout_rate = %input_dropout_rate
gtf.utils.models.mlp.dropout_rate = %dropout_rate
gtf.utils.models.mlp.dense_fn = @gtf.utils.models.dense
gtf.utils.models.mlp.normalization = %normalization

normalization = None

gtf.utils.models.dense.kernel_regularizer = %kernel_regularizer

kernel_regularizer = @tf.keras.regularizers.L2()
tf.keras.regularizers.L2.l2 = %weight_decay

optimizer = @tf.keras.optimizers.Adam()
tf.keras.optimizers.Adam.learning_rate = %lr
callbacks = [
    @tf.keras.callbacks.EarlyStopping(),
    @tf.keras.callbacks.TensorBoard(),
]
callbacks = []  # HACK
tf.keras.callbacks.TensorBoard.log_dir = '/tmp/gtf-logs/mlp'
# tf.keras.callbacks.TensorBoard.profile_batch = (10, 20)

tf.keras.callbacks.EarlyStopping.restore_best_weights = True
tf.keras.callbacks.EarlyStopping.monitor = %monitor
tf.keras.callbacks.EarlyStopping.mode = %mode
tf.keras.callbacks.EarlyStopping.patience = %patience

features_transform = (
    @gtf.data.transforms.row_normalize,
    @gtf.data.transforms.to_format,
)
gtf.utils.models.mlp.hack_input_spec = True
gtf.data.transforms.to_format.fmt = %fmt

include_transformed_features = True
batch_size = -1
fmt = "dense"
adjacency_features = ()
dual_features = ()
# monitor = 'val_acc'
# mode = 'max'
monitor = 'val_cross_entropy'
mode = 'min'
patience = 200
epochs = 2000
weight_decay = 5e-3
lr = 1e-2
units = (128,)
input_dropout_rate = None
dropout_rate = 0.5
largest_component_only = False
